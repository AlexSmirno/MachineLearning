{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5770570e",
   "metadata": {},
   "source": [
    "# Лабораторная работа №3\n",
    "\n",
    "ФИО:  Смирнов Александр Андреевич   \n",
    "Группа: БИВТ-20-1\n",
    "\n",
    "Отправлять можно следующими способами (**обязательно указать свое ФИО и группу в каком-либо виде**):\n",
    "1. Создать **приватный** репозиторий на github, добавить меня по нику (l3lush) в Collaborators (Settings -> Collaborators -> Add people)\n",
    "2. Отправить заполненный ноутбук мне на почту avmysh@gmail.com, либо m1603956@edu.misis.ru\n",
    "3. Отправить заполненный ноутбук мне в тг @l3lush. \n",
    "\n",
    "**Deadlines**:\n",
    "- soft -- **16.04.2023 23:59** (за сдачу в пределах этого времени +1 балл в табличку)\n",
    "- hard -- **30.04.2023 23:59**\n",
    "\n",
    "\n",
    "**Что необходимо сделать**:\n",
    "1. Заполнить все ячейки ниже кодом так, чтобы прошли все `assert`ы.\n",
    "2. **Побороть качество моей модели** (в конце ноутбука)\n",
    "\n",
    "\n",
    "**P.S. Используйте части кода с прошлой лабы для forward pass**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9b5d0",
   "metadata": {},
   "source": [
    "Сначала импортируем нужные библиотеки  \n",
    "Если чего-то нет локально, можно установить через pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ca7f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704002f",
   "metadata": {},
   "source": [
    "# Задача 1. Реализовать слой с функцией активации \"сигмоида\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0b72b",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1200px-Logistic-curve.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd5a25",
   "metadata": {},
   "source": [
    "Формула сигмоиды:\n",
    "$$\n",
    "f(x) = \\frac {1}{1 + e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2156cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidLayer():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        На будущее необходимо сохранить параметры и gradInput \n",
    "        \"\"\"\n",
    "        self.params = None\n",
    "        self.gradInput = None\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Реализовать forward pass\n",
    "        P.S. не забудьте сохранить X во внутреннюю переменную\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "\n",
    "        return 1/(1+np.exp(-X))\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        Реализовать bacward pass\n",
    "        \n",
    "        Необходимо возвращать градиенты в виде:\n",
    "        return self.gradInput, [self.gradW, self.gradB]\n",
    "        \n",
    "        P.S. если нет gradW и/или gradB, то возвращать пустой лист [], \n",
    "        вот так\n",
    "        return self.gradInput, []\n",
    "        \"\"\"\n",
    "        # TODO: write me\n",
    "        self.gradInput = dout * np.exp(-self.X)/(1+np.exp(-self.X))**2\n",
    "\n",
    "\n",
    "        if ((hasattr(self, \"gradW\") and hasattr(self, \"gradB\"))\n",
    "            and (self.gradW != None and self.gradB != None)):\n",
    "            return self.gradInput, [self.gradW, self.gradB]\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa22d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19460589 0.20407074 0.17488009]\n",
      " [0.1656316  0.10298473 0.08073351]\n",
      " [0.21590141 0.1403435  0.21416212]\n",
      " [0.21320927 0.03610846 0.05416308]\n",
      " [0.00737656 0.03121984 0.02882668]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "X = np.random.random(size=(100, 3))\n",
    "sigmoid = SigmoidLayer()\n",
    "output = sigmoid.forward(X)\n",
    "correct_answer = np.array([[0.57313782, 0.62961995, 0.54773438],\n",
    "                           [0.51696857, 0.68718368, 0.65843628],\n",
    "                           [0.65419284, 0.64005501, 0.50976449],\n",
    "                           [0.58851107, 0.7202462 , 0.51500666],\n",
    "                           [0.70350447, 0.70626044, 0.51279562]])\n",
    "assert np.isclose(output[:5], correct_answer).all()\n",
    "assert hasattr(sigmoid, \"params\"), \"Нет параметра params в реализованном классе\"\n",
    "assert hasattr(sigmoid, \"gradInput\"), \"Нет параметра gradInput в реализованном классе\"\n",
    "assert hasattr(sigmoid, \"X\"), \"Не сохранили X в реализованном классе\"\n",
    "\n",
    "\n",
    "dout = np.random.random(size=(100, 3))\n",
    "dInput, _ = sigmoid.backward(dout)\n",
    "print(dInput[:5])\n",
    "correct_dInput = np.array([[0.19460589, 0.20407074, 0.17488009],\n",
    "                           [0.1656316 , 0.10298473, 0.08073351],\n",
    "                           [0.21590141, 0.1403435 , 0.21416212],\n",
    "                           [0.21320927, 0.03610846, 0.05416308],\n",
    "                           [0.00737656, 0.03121984, 0.02882668]])\n",
    "assert np.isclose(dInput[:5], correct_dInput).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1aa776",
   "metadata": {},
   "source": [
    "# Задача 2. Реализовать слой с активацией гиперболического тангенса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c26084",
   "metadata": {},
   "source": [
    "![](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-05-27_at_4.23.22_PM_dcuMBJl.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920cf0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanhLayer():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        На будущее необходимо сохранить параметры и gradInput \n",
    "        \"\"\"\n",
    "        self.params = None\n",
    "        self.gradInput = None\n",
    "        \n",
    "        pass\n",
    "    \n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Реализовать forward pass\n",
    "        P.S. не забудьте сохранить X во внутреннюю переменную\n",
    "        \"\"\"\n",
    "        self.X = X.copy()\n",
    "\n",
    "        return (np.exp(X)-np.exp(-X))/(np.exp(X)+np.exp(-X))\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        Реализовать bacward pass\n",
    "        \n",
    "        Необходимо возвращать градиенты в виде:\n",
    "        return self.gradInput, [self.gradW, self.gradB]\n",
    "        \n",
    "        P.S. если нет gradW и/или gradB, то возвращать пустой лист [], \n",
    "        вот так\n",
    "        return self.gradInput, []\n",
    "        \"\"\"\n",
    "        # TODO: write me\n",
    "        dx = -(np.exp(self.X) - np.exp(-self.X))**2 / (np.exp(self.X) + np.exp(-self.X))**2 + 1\n",
    "        self.gradInput = dout * dx\n",
    "\n",
    "        if ((hasattr(self, \"gradW\") and hasattr(self, \"gradB\"))\n",
    "            and (self.gradW != None and self.gradB != None)):\n",
    "            return self.gradInput, [self.gradW, self.gradB]\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4088016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7301867  0.66854527 0.68068037]\n",
      " [0.66024164 0.27247731 0.23991181]\n",
      " [0.65163784 0.44479135 0.85566899]\n",
      " [0.77667226 0.08164937 0.21606773]\n",
      " [0.01811832 0.07567937 0.11508041]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "X = np.random.random(size=(100, 3))\n",
    "tanh = TanhLayer()\n",
    "output = tanh.forward(X)\n",
    "correct_answer = np.array([[0.28642281, 0.48582948, 0.18921297],\n",
    "                           [0.0677962 , 0.65669792, 0.57591821],\n",
    "                           [0.5632092 , 0.51946218, 0.03904306],\n",
    "                           [0.34328675, 0.73782249, 0.05997262],\n",
    "                           [0.69833441, 0.70505935, 0.05114899]])\n",
    "assert np.isclose(output[:5], correct_answer).all()\n",
    "assert hasattr(tanh, \"params\"), \"Нет параметра params в реализованном классе\"\n",
    "assert hasattr(tanh, \"gradInput\"), \"Нет параметра gradInput в реализованном классе\"\n",
    "assert hasattr(tanh, \"X\"), \"Не сохранили X в реализованном классе\"\n",
    "\n",
    "\n",
    "dout = np.random.random(size=(100, 3))\n",
    "dInput, _ = tanh.backward(dout)\n",
    "print(dInput[:5])\n",
    "correct_dInput = np.array([[0.7301867 , 0.66854527, 0.68068037],\n",
    "                           [0.66024164, 0.27247731, 0.23991181],\n",
    "                           [0.65163784, 0.44479135, 0.85566899],\n",
    "                           [0.77667226, 0.08164937, 0.21606773],\n",
    "                           [0.01811832, 0.07567937, 0.11508041]])\n",
    "assert np.isclose(dInput[:5], correct_dInput).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b44f7",
   "metadata": {},
   "source": [
    "# Задача 3. Реализовать функцию потерь MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15d7c2",
   "metadata": {},
   "source": [
    "В качестве интерактива-микрозадания, поищите формулу MSE в гугле 😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "919014f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss():\n",
    "    def forward(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Реализовать forward pass\n",
    "        \"\"\"\n",
    "        return sum(((y_true-y_pred)**2))/len(y_true)\n",
    "    \n",
    "    def backward(self, y_true, y_pred):\n",
    "        return 2*(y_pred - y_true)/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f14b8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "y_true = np.random.randint(0, 1000, size=(100))\n",
    "y_pred = np.random.randint(0, 1000, size=(100))\n",
    "mse = MSELoss()\n",
    "output = mse.forward(y_true, y_pred)\n",
    "correct_answer = 157953.51\n",
    "assert round(output) == round(correct_answer)\n",
    "\n",
    "dout = mse.backward(y_true, y_pred)\n",
    "right_dout = np.array([3.56, 1.24, 10.2, 7.68, 3.02, 9.04, -12.84, -2.16, 3.04, 0.24])\n",
    "assert np.isclose(dout[:10], right_dout).all()\n",
    "assert round(dout.sum(), 3) == 19.26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d40c5",
   "metadata": {},
   "source": [
    "# Задача 4. Реализовать каркас нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db70586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    \"\"\"\n",
    "    Линейный слой с семинаров, ничего менять не надо\n",
    "    \"\"\"\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.W = np.random.randn(in_size, out_size)\n",
    "        self.params = [self.W]\n",
    "        self.gradW = None\n",
    "        self.gradInput = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X.copy()\n",
    "        output = X.dot(self.W)\n",
    "        return output\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        self.gradW = self.X.T.dot(dout)\n",
    "        self.gradInput = dout.dot(self.W.T)\n",
    "        return self.gradInput, [self.gradW]\n",
    "\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, loss_func):\n",
    "        \"\"\"\n",
    "        Необходимо, чтобы нейросеть знала все о своей конфигурации.\n",
    "        1. Создайте внутренние переменные layers, params и grads как пустые листы.\n",
    "        2. Во внутреннюю переменную loss_func положите значение полученной переменной loss_func.\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.loss_func = loss_func\n",
    "        pass\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        \"\"\"\n",
    "        Функция добавления слоев в нейросеть.\n",
    "        Необходимо, чтобы обновлялись (расширялись) внутренние переменные,\n",
    "        ответственные за слои и параметры этих самых слоев, которые мы инициализировали\n",
    "        в __init__ методе.\n",
    "        \"\"\"\n",
    "        self.layers.append(layer)\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Реализовать forward pass для всей нейросети.\n",
    "        Т.е. реализовать forward pass по каждому слою, и в конце выдать результат \n",
    "        \"\"\"\n",
    "        for i in range (self.layers.__len__()):\n",
    "             X = self.layers[i].forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        Реализовать backward pass для всей нейросети.\n",
    "        Т.е. реализовать backward pass по каждому слою в обратном порядке\n",
    "        Каждый слой возвращает dout (проталкиваем градиент далее) \n",
    "        и grad (градиенты параметров для их обновления)\n",
    "        Все полученные градиенты параметров необходимо добавить во внутреннюю \n",
    "        переменную self.grads\n",
    "        В конце необходимо вернуть self.grads\n",
    "        В начале необходимо обнулять градиенты\n",
    "        \"\"\"\n",
    "        self.clear_grad_param()\n",
    "        \n",
    "        for i in range(self.layers.__len__() - 1, -1, -1):\n",
    "             dout, grad = self.layers[i].backward(dout)\n",
    "             self.grads.append(grad)\n",
    "\n",
    "        return self.grads\n",
    "\n",
    "    def train_step(self, X, y):\n",
    "        \"\"\"\n",
    "        Функция для проведения одного шага тренировки модели\n",
    "        \n",
    "        Что необходимо сделать:\n",
    "        1. Пропустить полученные данные через сеть\n",
    "        2. Получить значение loss функции\n",
    "        3. Получить градиенты loss функции\n",
    "        4. Полученные от loss функции градиенты запустить в сеть назад\n",
    "        \n",
    "        Возвращаем значение лосс функции из пункта 2 и градиенты из пункта 4.\n",
    "        \"\"\"\n",
    "        X = self.forward(X)\n",
    "        loss = self.loss_func.forward(X, y)\n",
    "        self.backward(self.loss_func.backward(y, X))\n",
    "        grads = self.grads\n",
    "\n",
    "        return loss, grads\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Функция для предсказания при заданных Х.\n",
    "        По большому счету, необходимо просто прогнать forward pass\n",
    "        и вернуть полученные значения.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.forward(X)\n",
    "    \n",
    "    def dispGradParam(self):\n",
    "        \"\"\"\n",
    "        Функция для принта градиентов, уже готовая\n",
    "        \"\"\"\n",
    "        print(self.grads)\n",
    "    \n",
    "    def clear_grad_param(self):\n",
    "        \"\"\"\n",
    "        Функция для очищения градиентов, уже готовая\n",
    "        \"\"\"\n",
    "        self.grads = []\n",
    "    \n",
    "    \n",
    "nn = NN(MSELoss())\n",
    "\n",
    "assert hasattr(nn, \"layers\")\n",
    "assert hasattr(nn, \"params\")\n",
    "assert hasattr(nn, \"grads\")\n",
    "assert hasattr(nn, \"loss_func\")\n",
    "assert isinstance(nn.loss_func, MSELoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f21c8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "X = np.random.random(size=(100, 3))\n",
    "nn = NN(MSELoss())\n",
    "\n",
    "linear1 = LinearLayer(3, 5)\n",
    "nn.add_layer(linear1)\n",
    "\n",
    "sigmoid1 = SigmoidLayer()\n",
    "nn.add_layer(sigmoid1)\n",
    "\n",
    "linear2 = LinearLayer(5, 1)\n",
    "nn.add_layer(linear2)\n",
    "\n",
    "sigmoid2 = SigmoidLayer()\n",
    "nn.add_layer(sigmoid2)\n",
    "\n",
    "output_nn = nn.forward(X)\n",
    "\n",
    "assert round(output_nn.sum()) == 65\n",
    "\n",
    "y = np.random.randint(0, 2, size=100).reshape(-1, 1)\n",
    "\n",
    "nn_predict = nn.predict(X)\n",
    "assert (output_nn == nn.predict(X)).all()\n",
    "\n",
    "loss, grads = nn.train_step(X, y)\n",
    "right_loss = np.array([0.24705916])\n",
    "\n",
    "assert np.isclose(loss, right_loss)\n",
    "assert grads[0] == []\n",
    "assert round(grads[1][0].sum(), 4) == 0.0394\n",
    "assert grads[2] == []\n",
    "assert round(grads[3][0].sum(), 4) == 0.0077"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f7edb",
   "metadata": {},
   "source": [
    "# Задача 4.1. Реализовать нарезку датасета на минибатчи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e3692c",
   "metadata": {},
   "source": [
    "Минибатч -- это кусочек данных определенного размера, который мы можем варьировать сами  \n",
    "Например, если в датасете 1000 записей, а мы хотим поставить размер батча в 50 наблюдений, то мы получим 20 батчей с 50 наблюдениями в каждом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a803c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch(X, y, minibatch_size):\n",
    "    \"\"\"\n",
    "    Функция для нарезания X и у на куски размером minibatch_size.\n",
    "    Возвращает данные в виде: [(X_batch1, y_batch1), \n",
    "                               (X_batch2, y_batch2), \n",
    "                               ...]\n",
    "    \"\"\"\n",
    "    if (len(X) % minibatch_size != 0):\n",
    "        pass\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    result = []\n",
    "    while (i <= len(X)):\n",
    "        result.append((X[i: i + minibatch_size], y[i: i + minibatch_size]))\n",
    "        i += minibatch_size\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29d0e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "BATCH_SIZE = 33\n",
    "X = np.random.random(size=(100, 3))\n",
    "y = np.random.randint(0, 2, size=100).reshape(-1, 1)\n",
    "\n",
    "minibatches = minibatch(X, y, BATCH_SIZE)\n",
    "X_batch0, y_batch0 = minibatches[0]\n",
    "correct_y_batch0 = np.array([[0], [0], [0], [1], [1]])\n",
    "assert len(minibatches) == 4\n",
    "assert round(X_batch0.sum(), 3) == 50.216\n",
    "assert (y_batch0[:5] == correct_y_batch0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f86a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(velocity, params, grads, learning_rate=0.001, mu=0.9):\n",
    "    \"\"\"\n",
    "    Обратите внимание на эту функцию\n",
    "    Здесь происходит чуть хитрое обновление весов\n",
    "    На семинаре поговорим об этом\n",
    "    \"\"\"\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = mu * v[i] + learning_rate * g[i]\n",
    "            p[i] -= v[i]\n",
    "            \n",
    "\n",
    "def plot_train_process(train_acc_list, val_acc_list, \n",
    "                       mean_train_loss_list, mean_val_loss_list):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    axes[0].set_title('Mean absolute error')\n",
    "    axes[1].set_title('Loss')\n",
    "    \n",
    "    axes[0].plot(train_acc_list, label='train')\n",
    "    axes[0].plot(val_acc_list, label='test')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].plot(mean_train_loss_list, label='train')\n",
    "    axes[1].plot(mean_val_loss_list, label='test')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def check_accuracy(y_true, y_pred):\n",
    "    return np.mean(abs(y_true - y_pred))\n",
    "\n",
    "\n",
    "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9,\n",
    "                 verbose=True, X_val=None, y_val=None, nesterov=True, draw_each_iters=5):\n",
    "    val_loss_epoch = []\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "\n",
    "    c = 0 \n",
    "\n",
    "    mean_train_loss_list = []\n",
    "    mean_val_loss_list = []\n",
    "    train_acc_list = []\n",
    "    val_acc_list = []\n",
    "    for n_iter in range(epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "\n",
    "        # iterate over mini batches\n",
    "        for X_mini, y_mini in minibatches:\n",
    "\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update(velocity, net.params, grads,\n",
    "                   learning_rate=learning_rate, mu=mu)\n",
    "\n",
    "        for X_mini_val, y_mini_val in minibatches_val:\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "\n",
    "\n",
    "        # accuracy of model at end of epoch after all mini batch updates   \n",
    "\n",
    "        if verbose:\n",
    "            m_train = X_train.shape[0]\n",
    "            m_val = X_val.shape[0]\n",
    "            y_train_pred = np.array([], dtype=\"int64\")\n",
    "            y_val_pred = np.array([], dtype=\"int64\")\n",
    "\n",
    "            for i in range(0, m_train, minibatch_size):\n",
    "                X_tr = X_train[i:i + minibatch_size, : ]\n",
    "                y_tr = y_train[i:i + minibatch_size, ]\n",
    "                y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
    "\n",
    "            for i in range(0, m_val, minibatch_size):\n",
    "                X_va = X_val[i:i + minibatch_size, : ]\n",
    "                y_va = y_val[i:i + minibatch_size, ]\n",
    "                y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
    "        \n",
    "            train_acc = check_accuracy(y_train, y_train_pred)\n",
    "            val_acc = check_accuracy(y_val, y_val_pred)\n",
    "            mean_train_loss = sum(loss_batch) / float(len(loss_batch))\n",
    "            mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
    "            \n",
    "            train_acc_list.append(train_acc)\n",
    "            val_acc_list.append(val_acc)\n",
    "            \n",
    "            mean_train_loss_list.append(mean_train_loss)\n",
    "            mean_val_loss_list.append(mean_val_loss)\n",
    "\n",
    "            # early stopping with patience = 5 on val loss\n",
    "            if len(val_loss_epoch) == 0:\n",
    "                val_loss_epoch.append(mean_val_loss)\n",
    "            else:\n",
    "                for j in val_loss_epoch[-5:]:\n",
    "                    if mean_val_loss > j:\n",
    "                        c += 1\n",
    "                    else:\n",
    "                        c = 0\n",
    "                if c > 5:\n",
    "                    print('Early stopping')\n",
    "                    return net\n",
    "                else:\n",
    "                    c = 0\n",
    "                    val_loss_epoch.append(mean_val_loss)  \n",
    "                    \n",
    "            if n_iter % draw_each_iters == 0:\n",
    "                clear_output(True)\n",
    "                plot_train_process(train_acc_list, val_acc_list, \n",
    "                                   mean_train_loss_list, mean_val_loss_list)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e827d",
   "metadata": {},
   "source": [
    "# Пробуем обучить нейросеть на игрушечных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7e8d0e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train:\n",
      "[[0.     0.0001 0.0002 0.0003]\n",
      " [0.0004 0.0005 0.0006 0.0007]\n",
      " [0.0008 0.0009 0.001  0.0011]\n",
      " [0.0012 0.0013 0.0014 0.0015]\n",
      " [0.0016 0.0017 0.0018 0.0019]]\n",
      "y train:\n",
      "[[0.0006]\n",
      " [0.0022]\n",
      " [0.0038]\n",
      " [0.0054]\n",
      " [0.007 ]]\n",
      "\n",
      "X test:\n",
      "[[0.1    0.1001 0.1002 0.1003]\n",
      " [0.1004 0.1005 0.1006 0.1007]\n",
      " [0.1008 0.1009 0.101  0.1011]\n",
      " [0.1012 0.1013 0.1014 0.1015]\n",
      " [0.1016 0.1017 0.1018 0.1019]]\n",
      "y test:\n",
      "[[0.4006]\n",
      " [0.4022]\n",
      " [0.4038]\n",
      " [0.4054]\n",
      " [0.407 ]]\n"
     ]
    }
   ],
   "source": [
    "# Get preprocessed training and validation data\n",
    "\n",
    "X_train = np.arange(1000).reshape(250, 4) / 1e4\n",
    "y_train = X_train.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "X_test = np.arange(1000, 2000).reshape(250, 4) / 1e4\n",
    "y_test = X_val.sum(axis=1).reshape(-1, 1) \n",
    "\n",
    "print(\"X train:\")\n",
    "print(X_train[:5])\n",
    "print(\"y train:\")\n",
    "print(y_train[:5])\n",
    "print()\n",
    "print(\"X test:\")\n",
    "print(X_test[:5])\n",
    "print(\"y test:\")\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03661811",
   "metadata": {},
   "source": [
    "Для наглядности визуализируем обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5901688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_each = 15\n",
    "\n",
    "plt.scatter(X_train[::plot_each, 0], y_train[::plot_each], label='train')\n",
    "plt.scatter(X_test[::plot_each, 0], y_test[::plot_each], label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c601f0a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\МИСиС\\6 Семестр\\MachineLearning\\MachineLearning\\lab_3.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# add some layers\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39madd_layer(LinearLayer(\u001b[39m4\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m train(model, X_train, y_train, minibatch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, epoch\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m            learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, X_val\u001b[39m=\u001b[39;49mX_test, y_val\u001b[39m=\u001b[39;49my_test, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32md:\\МИСиС\\6 Семестр\\MachineLearning\\MachineLearning\\lab_3.ipynb Cell 29\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu, verbose, X_val, y_val, nesterov, draw_each_iters)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# iterate over mini batches\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mfor\u001b[39;00m X_mini, y_mini \u001b[39min\u001b[39;00m minibatches:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     loss, grads \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mtrain_step(X_mini, y_mini)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     loss_batch\u001b[39m.\u001b[39mappend(loss)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     update(velocity, net\u001b[39m.\u001b[39mparams, grads,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m            learning_rate\u001b[39m=\u001b[39mlearning_rate, mu\u001b[39m=\u001b[39mmu)\n",
      "\u001b[1;32md:\\МИСиС\\6 Семестр\\MachineLearning\\MachineLearning\\lab_3.ipynb Cell 29\u001b[0m in \u001b[0;36mNN.train_step\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mФункция для проведения одного шага тренировки модели\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mВозвращаем значение лосс функции из пункта 2 и градиенты из пункта 4.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(X)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_func\u001b[39m.\u001b[39;49mforward(X, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_func\u001b[39m.\u001b[39mbackward(y, X))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrads\n",
      "\u001b[1;32md:\\МИСиС\\6 Семестр\\MachineLearning\\MachineLearning\\lab_3.ipynb Cell 29\u001b[0m in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, y_true, y_pred):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    Реализовать forward pass\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%D0%9C%D0%98%D0%A1%D0%B8%D0%A1/6%20%D0%A1%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/MachineLearning/MachineLearning/lab_3.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39;49m(((y_true\u001b[39m-\u001b[39;49my_pred)\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m))\u001b[39m/\u001b[39;49m\u001b[39mlen\u001b[39;49m(y_true)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# define neural net\n",
    "model = NN(MSELoss())\n",
    "\n",
    "# add some layers\n",
    "model.add_layer(LinearLayer(4, 1))\n",
    "\n",
    "model = train(model, X_train, y_train, minibatch_size=10, epoch=100,\n",
    "           learning_rate=0.01, X_val=X_val, y_val=y_val, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cd30fd",
   "metadata": {},
   "source": [
    "Если все получилось (лосс падает, ошибка падает), то микро-ура  \n",
    "Теперь самое время начать работать с реальными данными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61908db6",
   "metadata": {},
   "source": [
    "# Задача 5. Обучить нейросеть на реальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b282565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "DATA_URL = \"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\"\n",
    "data = pd.read_csv(DATA_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ac9eaf",
   "metadata": {},
   "source": [
    "Постановки задачи следующая -- необходимо предсказать размер страховки для человека на основании собранных данных:\n",
    "- возраст (age)\n",
    "- пол (sex)\n",
    "- индекс массы тела (bmi)\n",
    "- количество детей (children)\n",
    "- курильщик или нет (smoker)\n",
    "- регион человека (region)  \n",
    "----\n",
    "Целевая переменная представлена в столбце `charges`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d8799",
   "metadata": {},
   "source": [
    "Смотрим на данные глазами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0799b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d918cb9",
   "metadata": {},
   "source": [
    "Закодируем категориальные признаки через One Hot Encoding  \n",
    "![](https://i.imgur.com/mtimFxh.png)  \n",
    "Из каждого уникального значения категориального признака создается новый столбец с его значением  \n",
    "Например, для признака `sex` есть два уникальных значения `{\"female\", \"male\"}`  \n",
    "Мы создадим два новых столбца с названиями `sex_female` и `sex_male`, где будут представлены только 0 или 1, в зависимости от того, какого пола человек в выборке  \n",
    "В библиотеке pandas это можно сделать через метод `pd.get_dummies()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c714d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['sex', 'smoker', 'region']\n",
    "dummy_data = pd.get_dummies(data[cat_columns])\n",
    "data.drop(cat_columns, axis=1, inplace=True)\n",
    "data = pd.concat([data, dummy_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfefd2e7",
   "metadata": {},
   "source": [
    "Посмотрим на распределение целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02312a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['charges'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02afa07",
   "metadata": {},
   "source": [
    "Есть очень большие значения целевой переменной, которые будут вызывать большой градиент  \n",
    "Поэтому давайте будем предсказывать не прямое значение, а логарифм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac94d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['charges_log'] = np.log(data['charges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ad227",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['charges_log'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5490a6bf",
   "metadata": {},
   "source": [
    "Удалим целевую переременную в сыром виде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0902ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['charges'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7555ddf",
   "metadata": {},
   "source": [
    "Нейросети плохо работают с числовыми признаками в сыром виде, поэтому хорошо будет их отшаклировать тоже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f4c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standart_scale_feature(feature_array):\n",
    "    mean = np.mean(feature_array)\n",
    "    std = np.std(feature_array)\n",
    "    output = (feature_array - mean) / std\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822055b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\"age\", \"bmi\", \"children\"]\n",
    "for feature in num_features:\n",
    "    data[feature] = standart_scale_feature(data[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfeee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297ed381",
   "metadata": {},
   "source": [
    "Теперь формируем обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b36e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_name = 'charges_log'\n",
    "X = data.drop([y_name], axis=1).to_numpy()\n",
    "y = data[y_name].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236fba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X:\")\n",
    "print(X[:5])\n",
    "print(\"y:\")\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf34a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdeadb2",
   "metadata": {},
   "source": [
    "Возьмем первые 1000 наблюдений для обучения модели, а оставшиеся для теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c48b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = 1000\n",
    "X_train = X[:split_idx]\n",
    "y_train = y[:split_idx]\n",
    "X_test = X[split_idx:]\n",
    "y_test = y[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e8155",
   "metadata": {},
   "source": [
    "Теперь ваша задача натренировать нейросеть так, чтобы она научилась предсказывать размер страховки для конкретного человека"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d7189",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6d4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3  # с этим параметром придется поиграться\n",
    "N_EPOCHS = 10  # c этим тоже\n",
    "\n",
    "# инициализируем нейросеть\n",
    "model = NN(MSELoss())\n",
    "\n",
    "# TODO: добавьте слои в сеть\n",
    "\n",
    "model = train(model, X_train, y_train, minibatch_size=128, epoch=N_EPOCHS,\n",
    "           learning_rate=LEARNING_RATE, X_val=X_test, y_val=y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c0ec4",
   "metadata": {},
   "source": [
    "Оценим работу модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "mean_error_train = np.mean(abs(y_train - y_train_pred))\n",
    "print(f\"Средняя абсолютная ошибка на трейне: {mean_error_train:.3f}\")\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "mean_error_test = np.mean(abs(y_test - y_test_pred))\n",
    "print(f\"Средняя абсолютная ошибка на тесте: {mean_error_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9dbc89",
   "metadata": {},
   "source": [
    "У меня получилась средняя ошибка на трейне **0.766**, на тесте **0.835**  \n",
    "**Эти значения надо побить** (ваши значения должны быть меньше моих)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e934a5",
   "metadata": {},
   "source": [
    "Выше мы оценивали логарифмы, давайте оценим истинные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_true_values = np.exp(y_train_pred)\n",
    "y_train_true_values = np.exp(y_train)\n",
    "mean_error_train = np.mean(abs(y_train_true_values - y_train_pred_true_values))\n",
    "print(f\"Средняя ошибка на трейне: {mean_error_train:.2f}\")\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_true_values = np.exp(y_test_pred)\n",
    "y_test_true_values = np.exp(y_test)\n",
    "mean_error_test = np.mean(abs(y_test_true_values - y_test_pred_true_values))\n",
    "print(f\"Средняя ошибка на тесте: {mean_error_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1117c4",
   "metadata": {},
   "source": [
    "У меня получилась средняя ошибка на трейне **8090.09**, на тесте **9007.43**  \n",
    "**Эти значения тоже надо побить** (ваши значения должны быть меньше моих)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc0cc42",
   "metadata": {},
   "source": [
    "Оценим среднюю абсолютную процентную ошибку (метрика называется MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e468d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_count(y_true, y_pred):\n",
    "    return np.mean((abs(y_true - y_pred) / y_true) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a3b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_train = mape_count(y_train_true_values, y_train_pred_true_values)\n",
    "mape_test = mape_count(y_test_true_values, y_test_pred_true_values)\n",
    "print(f\"MAPE train: {mape_train:.2f}%\")\n",
    "print(f\"MAPE test: {mape_test:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef147a1",
   "metadata": {},
   "source": [
    "У меня получилось MAPE на трейне **95.11%**, на тесте **89.10%**  \n",
    "**Эти значения надо побить** (ваши значения должны быть меньше моих)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0d2de",
   "metadata": {},
   "source": [
    "## Если все получилось, то я вас поздравляю :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03456702",
   "metadata": {},
   "source": [
    "![](http://sun9-16.userapi.com/impf/c840737/v840737590/55ded/Ns6wztlxubY.jpg?size=604x466&quality=96&sign=e4647d7e87db4c211d138163f60ea33b&type=album)  \n",
    "плюс за то, что завершил(а) эту лабу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53de20a",
   "metadata": {},
   "source": [
    "P.S. ниже есть _необязательная_ задача для жаждущих еще поупражняться"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f54983",
   "metadata": {},
   "source": [
    "# Задача 6\\*. Попробуйте сделать настоящий линейный слой\n",
    "То есть добавить еще и вектор смещений B, и написать соответствующий функционал в `forward` и `backward` методах  \n",
    "Далее собрать из нейросеть при помощи полноценных линейных слоев и посмотреть, улучшится ли качество при таком подходе"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
